{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract some images from the Mini COCO2014 Dataset: https://www.kaggle.com/datasets/nagasai524/mini-coco2014-dataset-for-image-captioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T16:18:22.296311Z",
     "iopub.status.busy": "2024-12-09T16:18:22.295059Z",
     "iopub.status.idle": "2024-12-09T16:18:22.310256Z",
     "shell.execute_reply": "2024-12-09T16:18:22.309093Z",
     "shell.execute_reply.started": "2024-12-09T16:18:22.296254Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import sys \n",
    "import json \n",
    "import numpy as np \n",
    "import pandas \n",
    "import random \n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T16:18:22.312960Z",
     "iopub.status.busy": "2024-12-09T16:18:22.312463Z",
     "iopub.status.idle": "2024-12-09T16:18:22.510574Z",
     "shell.execute_reply": "2024-12-09T16:18:22.509157Z",
     "shell.execute_reply.started": "2024-12-09T16:18:22.312913Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image_id': 299675,\n",
       "  'id': 328,\n",
       "  'caption': 'A white square kitchen with tile floor that needs repairs '},\n",
       " {'image_id': 513461,\n",
       "  'id': 572,\n",
       "  'caption': 'A surfer, a woman, and a child walk on the beach.'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('captions.json', 'r') as file: \n",
    "    data = json.load(file)\n",
    "data[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T16:18:22.512304Z",
     "iopub.status.busy": "2024-12-09T16:18:22.511965Z",
     "iopub.status.idle": "2024-12-09T16:18:22.594119Z",
     "shell.execute_reply": "2024-12-09T16:18:22.592967Z",
     "shell.execute_reply.started": "2024-12-09T16:18:22.512272Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_id': 9, 'id': 661611, 'caption': 'Closeup of bins of food that include broccoli and bread.'}\n",
      "{'image_id': 9, 'id': 661977, 'caption': 'A meal is presented in brightly colored plastic trays.'}\n",
      "{'image_id': 9, 'id': 663627, 'caption': 'there are containers filled with different kinds of foods'}\n",
      "{'image_id': 9, 'id': 666765, 'caption': 'Colorful dishes holding meat, vegetables, fruit, and bread.'}\n",
      "{'image_id': 9, 'id': 667602, 'caption': 'A bunch of trays that have different food.'}\n",
      "{'image_id': 61, 'id': 444409, 'caption': 'They are brave for riding in the jungle on those elephants.'}\n",
      "{'image_id': 61, 'id': 446671, 'caption': 'SOME PEOPLE IN THE WOODS RIDING TWO ELEPHANTS'}\n",
      "{'image_id': 61, 'id': 452062, 'caption': 'Some people who are riding on top of elephants.'}\n",
      "{'image_id': 61, 'id': 452272, 'caption': 'there are people riding elephants in the middle of a forest'}\n",
      "{'image_id': 61, 'id': 455584, 'caption': 'Several elephants in the jungle carrying people on their backs'}\n"
     ]
    }
   ],
   "source": [
    "# we want to sort \"data\" based on the image_id\n",
    "sorted_data = sorted(data, key = lambda x: x['image_id'])\n",
    "print(*sorted_data[:10], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T16:18:22.597180Z",
     "iopub.status.busy": "2024-12-09T16:18:22.596686Z",
     "iopub.status.idle": "2024-12-09T16:18:32.391499Z",
     "shell.execute_reply": "2024-12-09T16:18:32.390007Z",
     "shell.execute_reply.started": "2024-12-09T16:18:22.597137Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Closeup of bins of food that include broccoli and bread .',\n",
       " 'A meal is presented in brightly colored plastic trays .',\n",
       " 'there are containers filled with different kinds of foods',\n",
       " 'Colorful dishes holding meat , vegetables , fruit , and bread .',\n",
       " 'A bunch of trays that have different food .']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we have the \"sorted_data\" by the image_id \n",
    "# we will create a dictionary in the format {'image_id': list of reference captions}\n",
    "my_data = defaultdict(list)\n",
    "for infor in sorted_data: \n",
    "    if len(my_data[infor['image_id']]) == 5: # since some images have more than 5 captions\n",
    "        continue \n",
    "    my_data[infor['image_id']].append(' '.join(word_tokenize(infor['caption'])))\n",
    "\n",
    "my_data[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T16:18:32.394033Z",
     "iopub.status.busy": "2024-12-09T16:18:32.393471Z",
     "iopub.status.idle": "2024-12-09T16:18:32.411252Z",
     "shell.execute_reply": "2024-12-09T16:18:32.409905Z",
     "shell.execute_reply.started": "2024-12-09T16:18:32.393977Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93915, 93915)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0 \n",
    "for captions in list(my_data.values()):\n",
    "    cnt += len(captions)\n",
    "cnt, len(my_data) * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T16:18:32.413399Z",
     "iopub.status.busy": "2024-12-09T16:18:32.412909Z",
     "iopub.status.idle": "2024-12-09T16:18:32.494318Z",
     "shell.execute_reply": "2024-12-09T16:18:32.493100Z",
     "shell.execute_reply.started": "2024-12-09T16:18:32.413342Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# now we will randomly choose 9k images for our image captioning project \n",
    "image_ids = list(my_data.keys())\n",
    "n = 8200\n",
    "random_img_ids = random.sample(image_ids, n)\n",
    "\n",
    "# finally we will store all the image ids in the random_list with captions for each image id in the captions_coco.txt line by line \n",
    "with open('captions_coco.txt', 'w') as file:\n",
    "    file.write('image,caption\\n')\n",
    "    for img_id in random_img_ids:\n",
    "        for caption in my_data[img_id]:\n",
    "            file.write(f'''COCO_train2014_{str(img_id).rjust(12, '0')}.jpg,\"{caption}\"\\n''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Captions file \n",
    "CAPTIONS_FILE = 'captions_coco.txt'\n",
    "with open(CAPTIONS_FILE, 'r') as f: \n",
    "    captions_data = f.readlines()[1:]\n",
    "\n",
    "### Split dataset to 3 datasets: train (0.8), validation (0.1), test (0.1)\n",
    "\n",
    "image_captions_dict = defaultdict(list)\n",
    "\n",
    "for line in captions_data:\n",
    "    img_id, caption = line.strip().split(',', 1)\n",
    "    image_captions_dict[img_id].append(caption)\n",
    "    \n",
    "# Get a list of unique image IDs\n",
    "unique_image_ids = list(image_captions_dict.keys())\n",
    "\n",
    "# Split image IDs into train, val, test\n",
    "train_imgs, val_test_imgs = train_test_split(unique_image_ids, test_size=0.2, random_state=42)\n",
    "val_imgs, test_imgs = train_test_split(val_test_imgs, test_size=0.5, random_state=42)\n",
    "\n",
    "# Function to get captions and image IDs for each set\n",
    "def get_captions_and_ids(image_ids_subset):\n",
    "    subset_captions = []\n",
    "    subset_image_ids = []\n",
    "    for img_id in image_ids_subset:\n",
    "        captions = image_captions_dict[img_id]\n",
    "        subset_captions.extend(captions)\n",
    "        subset_image_ids.extend([img_id] * len(captions))\n",
    "    return subset_captions, subset_image_ids\n",
    "\n",
    "# Get captions and image IDs for each set\n",
    "train_captions, train_image_ids = get_captions_and_ids(train_imgs)\n",
    "val_captions, val_image_ids = get_captions_and_ids(val_imgs)\n",
    "test_captions, test_image_ids = get_captions_and_ids(test_imgs)\n",
    "\n",
    "# Write train.txt\n",
    "with open('train.txt', 'w') as f: \n",
    "    for image_id, caption in zip(train_image_ids, train_captions):\n",
    "        f.write(f\"{image_id},{caption}\\n\")\n",
    "\n",
    "# Write val.txt\n",
    "with open('val.txt', 'w') as f: \n",
    "    for image_id, caption in zip(val_image_ids, val_captions):\n",
    "        f.write(f\"{image_id},{caption}\\n\")\n",
    "\n",
    "# Write test.txt\n",
    "with open('test.txt', 'w') as f: \n",
    "    for image_id, caption in zip(test_image_ids, test_captions):\n",
    "        f.write(f\"{image_id},{caption}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2938312,
     "sourceId": 5060663,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "thanh309-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
